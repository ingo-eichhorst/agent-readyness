---
phase: 03-scoring-model
plan: 01
type: tdd
wave: 1
depends_on: []
files_modified:
  - pkg/types/scoring.go
  - internal/scoring/config.go
  - internal/scoring/config_test.go
  - internal/scoring/scorer.go
  - internal/scoring/scorer_test.go
autonomous: true

must_haves:
  truths:
    - "Piecewise linear interpolation maps raw metric values to 1-10 scores correctly"
    - "Composite score is normalized by sum of active category weights (not 1.0)"
    - "Tier classification assigns correct tier at boundary values (>= semantics)"
    - "Default config provides breakpoints for all 16 metrics across C1/C3/C6"
  artifacts:
    - path: "pkg/types/scoring.go"
      provides: "ScoredResult, CategoryScore, SubScore, TierRating types"
      exports: ["ScoredResult", "CategoryScore", "SubScore"]
    - path: "internal/scoring/config.go"
      provides: "ScoringConfig, MetricThresholds, Breakpoint, DefaultConfig"
      exports: ["ScoringConfig", "DefaultConfig", "Breakpoint", "MetricThresholds", "CategoryConfig", "TierConfig"]
    - path: "internal/scoring/scorer.go"
      provides: "Scorer type with Interpolate, computeComposite, classifyTier"
      exports: ["Scorer", "Interpolate"]
  key_links:
    - from: "internal/scoring/scorer.go"
      to: "internal/scoring/config.go"
      via: "Scorer.Config field"
      pattern: "Config.*ScoringConfig"
    - from: "internal/scoring/scorer.go"
      to: "pkg/types/scoring.go"
      via: "returns ScoredResult"
      pattern: "types\\.ScoredResult"
---

<objective>
Create the scoring foundation: types, config with default breakpoints, piecewise linear interpolation, composite scoring, and tier classification.

Purpose: This is the mathematical core of the scoring model. Every scoring function is a pure function (input -> output) making it ideal for TDD. Getting the interpolation, weight normalization, and tier boundaries correct here prevents cascading bugs in category scoring.

Output: `pkg/types/scoring.go` with result types, `internal/scoring/config.go` with default breakpoints for all 16 metrics, `internal/scoring/scorer.go` with Interpolate, computeComposite, classifyTier functions -- all with passing tests.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/03-scoring-model/03-RESEARCH.md
@pkg/types/types.go
</context>

<feature>
  <name>Scoring Foundation: Types, Config, Interpolation, Composite, Tiers</name>
  <files>
    pkg/types/scoring.go
    internal/scoring/config.go
    internal/scoring/config_test.go
    internal/scoring/scorer.go
    internal/scoring/scorer_test.go
  </files>
  <behavior>
    This feature implements the mathematical core of the scoring model as pure functions.

    **Types (pkg/types/scoring.go):**
    - `ScoredResult` with `Categories []CategoryScore`, `Composite float64`, `Tier string`
    - `CategoryScore` with `Name string`, `Score float64`, `Weight float64`, `SubScores []SubScore`
    - `SubScore` with `MetricName string`, `RawValue float64`, `Score float64`, `Weight float64`, `Available bool`

    **Config (internal/scoring/config.go):**
    - `Breakpoint` struct: `Value float64`, `Score float64`
    - `MetricThresholds` struct: `Name string`, `Weight float64`, `Breakpoints []Breakpoint`
    - `CategoryConfig` struct: `Name string`, `Weight float64`, `Metrics []MetricThresholds`
    - `ScoringConfig` struct: `C1`, `C3`, `C6 CategoryConfig`, `Tiers []TierConfig`
    - `TierConfig` struct: `Name string`, `MinScore float64`
    - `DefaultConfig()` returns config with breakpoints for all 16 metrics per research doc

    Default breakpoints (from research, all sorted by Value ascending):
    - C1 (weight 0.25): complexity_avg (0.25), func_length_avg (0.20), file_size_avg (0.15), afferent_coupling_avg (0.15), efferent_coupling_avg (0.10), duplication_rate (0.15)
    - C3 (weight 0.20): max_dir_depth (0.20), module_fanout_avg (0.20), circular_deps (0.25), import_complexity_avg (0.15), dead_exports (0.20)
    - C6 (weight 0.15): test_to_code_ratio (0.25), coverage_percent (0.30), test_isolation (0.15), assertion_density_avg (0.15), test_file_ratio (0.15)

    Tier defaults (sorted descending by MinScore):
    - Agent-Ready >= 8.0, Agent-Assisted >= 6.0, Agent-Limited >= 4.0, Agent-Hostile >= 1.0

    **Interpolation (internal/scoring/scorer.go):**
    This implements SCORE-04 (piecewise linear interpolation requirement).
    - `Interpolate(breakpoints []Breakpoint, rawValue float64) float64`
    - Clamps below first breakpoint to first score
    - Clamps above last breakpoint to last score
    - Linear interpolation between adjacent breakpoints

    Cases:
    - Interpolate([{1,10},{5,8},{10,6},{20,3},{40,1}], 0) -> 10.0 (clamp below)
    - Interpolate([{1,10},{5,8},{10,6},{20,3},{40,1}], 1) -> 10.0 (exact)
    - Interpolate([{1,10},{5,8},{10,6},{20,3},{40,1}], 3) -> 9.0 (midpoint)
    - Interpolate([{1,10},{5,8},{10,6},{20,3},{40,1}], 50) -> 1.0 (clamp above)
    - Interpolate([], 5) -> 5.0 (empty breakpoints = neutral)

    **Composite scoring:**
    - `computeComposite(categories []CategoryScore) float64`
    - Weighted average where weights come from config
    - CRITICAL: normalize by sum of active category weights, NOT 1.0
    - With C1(0.25), C3(0.20), C6(0.15) all scoring 10.0 -> composite = 10.0 (not 6.0)
    - Skip categories with score < 0 (unavailable)

    Cases:
    - All 10s: (10*0.25 + 10*0.20 + 10*0.15) / 0.60 = 10.0
    - Mixed: (8*0.25 + 6*0.20 + 7*0.15) / 0.60 = 7.08
    - Only C1: (8*0.25) / 0.25 = 8.0

    **Tier classification:**
    - `classifyTier(score float64) string`
    - Boundary semantics: >= MinScore (inclusive lower bound)

    Cases:
    - 8.0 -> "Agent-Ready"
    - 7.99 -> "Agent-Assisted"
    - 6.0 -> "Agent-Assisted"
    - 5.99 -> "Agent-Limited"
    - 4.0 -> "Agent-Limited"
    - 3.99 -> "Agent-Hostile"
    - 1.0 -> "Agent-Hostile"

    **categoryScore helper:**
    - Computes weighted average of sub-scores within a category
    - Skips sub-scores where Available == false (redistributes weight)
    - Empty sub-scores -> 5.0 (neutral default)
  </behavior>
  <implementation>
    1. Create `pkg/types/scoring.go` with ScoredResult, CategoryScore, SubScore types.
    2. Create `internal/scoring/config.go` with Breakpoint, MetricThresholds, CategoryConfig, ScoringConfig, TierConfig, DefaultConfig().
    3. Create `internal/scoring/scorer.go` with `Scorer` struct holding `*ScoringConfig`, plus exported `Interpolate` function and unexported `computeComposite`, `classifyTier`, `categoryScore` methods.
    4. Write tests first (RED), implement (GREEN), refactor if needed.

    Default breakpoint values for each metric (from research):

    C1 complexity_avg: [{1,10},{5,8},{10,6},{20,3},{40,1}]
    C1 func_length_avg: [{5,10},{15,8},{30,6},{60,3},{100,1}]
    C1 file_size_avg: [{50,10},{150,8},{300,6},{500,3},{1000,1}]
    C1 afferent_coupling_avg: [{0,10},{2,8},{5,6},{10,3},{20,1}]
    C1 efferent_coupling_avg: [{0,10},{2,8},{5,6},{10,3},{20,1}]
    C1 duplication_rate: [{0,10},{3,8},{8,6},{15,3},{50,1}]

    C3 max_dir_depth: [{1,10},{3,8},{5,6},{7,3},{10,1}]
    C3 module_fanout_avg: [{0,10},{3,8},{6,6},{10,3},{15,1}]
    C3 circular_deps: [{0,10},{1,6},{3,3},{5,2},{10,1}]
    C3 import_complexity_avg: [{1,10},{2,8},{4,6},{6,3},{8,1}]
    C3 dead_exports: [{0,10},{5,8},{15,6},{30,3},{50,1}]

    C6 test_to_code_ratio: [{0,1},{0.2,4},{0.5,6},{0.8,8},{1.5,10}]
    C6 coverage_percent: [{0,1},{30,4},{50,6},{70,8},{90,10}]
    C6 test_isolation: [{0,1},{40,4},{60,6},{80,8},{95,10}]
    C6 assertion_density_avg: [{0,1},{1,4},{2,6},{3,8},{5,10}]
    C6 test_file_ratio: [{0,1},{0.3,4},{0.5,6},{0.7,8},{0.9,10}]

    Note: "lower is better" metrics have descending scores (10->1), "higher is better" have ascending (1->10). The Interpolate function handles both naturally since it just interpolates between breakpoint scores regardless of direction.
  </implementation>
</feature>

<verification>
- `cd /Users/ingo/agent-readyness && go test ./internal/scoring/... -v` -- all tests pass
- `cd /Users/ingo/agent-readyness && go build ./...` -- compiles cleanly
- Test coverage for interpolation includes: below-clamp, exact-match, midpoint, above-clamp, empty-breakpoints
- Test coverage for composite includes: all-10s normalization, mixed scores, single-category
- Test coverage for tier includes: exact boundary values (8.0, 6.0, 4.0), just-below values
- DefaultConfig() returns config with exactly 6 C1 metrics, 5 C3 metrics, 5 C6 metrics
</verification>

<success_criteria>
- All scoring math functions have passing tests with table-driven cases
- Interpolate correctly handles both "lower is better" and "higher is better" breakpoint orderings
- Composite score of all-10s equals 10.0 (not 6.0) -- weight normalization works
- Tier boundaries use >= semantics -- score of exactly 8.0 is "Agent-Ready"
- DefaultConfig provides breakpoints for all 16 metrics
- Types in pkg/types/scoring.go are usable by other packages
- SCORE-04 verified: Interpolate tests prove piecewise linear interpolation works correctly (below-clamp, midpoint interpolation, above-clamp, and empty-breakpoints cases all demonstrate the piecewise linear algorithm)
</success_criteria>

<output>
After completion, create `.planning/phases/03-scoring-model/03-01-SUMMARY.md`
</output>
