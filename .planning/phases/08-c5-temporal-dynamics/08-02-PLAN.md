---
phase: 08-c5-temporal-dynamics
plan: 02
type: execute
wave: 2
depends_on: ["08-01"]
files_modified:
  - internal/analyzer/c5_temporal_test.go
  - internal/scoring/config_test.go
autonomous: true

must_haves:
  truths:
    - "C5 analyzer unit tests pass with fixture git log output covering all metric calculations"
    - "Tests verify graceful handling of missing .git, empty history, binary files, renames, and large commits"
    - "C5 scoring config test confirms all 5 metrics present with correct weights"
    - "End-to-end scan on this repository produces C5 scores in output"
  artifacts:
    - path: "internal/analyzer/c5_temporal_test.go"
      provides: "Unit tests for C5 analyzer"
      min_lines: 150
    - path: "internal/scoring/config_test.go"
      provides: "Test confirming C5 in DefaultConfig"
      contains: "C5"
  key_links:
    - from: "internal/analyzer/c5_temporal_test.go"
      to: "internal/analyzer/c5_temporal.go"
      via: "tests exercise parseGitLog, metric calculations, and Analyze"
      pattern: "C5Analyzer"
---

<objective>
Add comprehensive unit tests for C5 analyzer and verify end-to-end integration by running `ars scan` on a real git repository.

Purpose: Ensure C5 temporal analysis works correctly and produces meaningful scores.
Output: Passing test suite and verified end-to-end scan output with C5 scores.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/08-c5-temporal-dynamics/08-RESEARCH.md
@.planning/phases/08-c5-temporal-dynamics/08-01-SUMMARY.md
@internal/analyzer/c5_temporal.go
@internal/analyzer/c5_temporal_test.go
@internal/scoring/config_test.go
</context>

<tasks>

<task type="auto">
  <name>Task 1: C5 analyzer unit tests with fixture git log output</name>
  <files>
    internal/analyzer/c5_temporal_test.go
    internal/scoring/config_test.go
  </files>
  <action>
Create `internal/analyzer/c5_temporal_test.go` with the following test cases:

**Test parsing and metrics (use internal helper functions if exported, or test through Analyze):**

1. `TestC5Analyzer_NoGitDir`: Create a temp directory without `.git`. Call `Analyze()`. Assert result has `Available: false`, no error returned.

2. `TestC5Analyzer_RealRepo`: Use the actual project root (find it via `os.Getwd()` + walk up to find `.git`). Call `Analyze()`. Assert:
   - `Available: true`
   - `TotalCommits > 0`
   - `ChurnRate > 0`
   - `HotspotConcentration > 0`
   - No error returned

3. `TestC5Analyzer_Name`: Assert `Name()` returns `"C5: Temporal Dynamics"`.

4. `TestC5Analyzer_EmptyTargets`: Call `Analyze(nil)` or empty slice. Assert error returned.

5. `TestC5Analyzer_Category`: Call Analyze on real repo, assert `result.Category == "C5"` and `result.Metrics["c5"]` is `*types.C5Metrics`.

**If the internal parsing functions are not exported, test them indirectly through the Analyze method on the real repo. The key verification is that the analyzer produces reasonable non-zero metrics on a real git repository.**

**Scoring config test addition:**
In `internal/scoring/config_test.go`, add a test (or extend existing) that verifies:
- `DefaultConfig().Categories["C5"]` exists
- Has Name "Temporal Dynamics"
- Has Weight 0.10
- Has 5 metrics: churn_rate, temporal_coupling_pct, author_fragmentation, commit_stability, hotspot_concentration
- Each metric has non-empty Breakpoints

Follow existing test patterns in the file. Use table-driven tests where appropriate.
  </action>
  <verify>
Run `go test ./internal/analyzer/ -run TestC5 -v` -- all C5 tests pass.
Run `go test ./internal/scoring/ -v` -- config tests pass including C5.
Run `go test ./...` -- full test suite passes.
  </verify>
  <done>
C5 unit tests cover: missing .git graceful handling, real repo analysis with non-zero metrics, analyzer name and category, empty targets error. Scoring config test confirms C5 category with all 5 metrics. Full test suite passes.
  </done>
</task>

<task type="auto">
  <name>Task 2: End-to-end verification scan</name>
  <files></files>
  <action>
1. Build the binary: `go build -o ars ./`

2. Run scan on this repository: `./ars scan .`
   - Verify output includes C5: Temporal Dynamics section with scores
   - Verify C5 metrics appear (churn rate, temporal coupling, author fragmentation, commit stability, hotspot concentration)
   - Verify composite score now includes C5 weight

3. Run scan with JSON output: `./ars scan . --json`
   - Verify JSON includes C5 category with sub-scores

4. Run scan on a temp directory without .git:
   - Create temp dir with a single .go file
   - Run `./ars scan /tmp/test-dir`
   - Verify C5 shows as unavailable (not a crash)

5. If any issues found during verification, fix them in the source files.

6. Run full test suite one final time: `go test ./...`
  </action>
  <verify>
`./ars scan .` produces output with C5 scores.
`./ars scan . --json` includes C5 in JSON output.
Scan on non-git directory does not crash.
`go test ./...` passes.
  </verify>
  <done>
End-to-end scan on a real git repository produces C5 temporal dynamics scores. JSON output includes C5 category. Non-git directories handled gracefully. All tests pass.
  </done>
</task>

</tasks>

<verification>
- `go test ./...` passes with all C5 tests
- `./ars scan .` shows C5 scores in terminal output
- `./ars scan . --json` shows C5 in JSON output
- Non-git directory scan does not crash
- Composite score reflects C5 contribution
</verification>

<success_criteria>
- All C5 unit tests pass
- End-to-end scan on real git repo produces meaningful C5 scores
- Non-git directories handled gracefully (Available: false, no crash)
- Full test suite (`go test ./...`) passes
- C5 appears in both terminal and JSON output formats
</success_criteria>

<output>
After completion, create `.planning/phases/08-c5-temporal-dynamics/08-02-SUMMARY.md`
</output>
