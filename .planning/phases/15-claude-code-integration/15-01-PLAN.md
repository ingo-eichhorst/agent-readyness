---
phase: 15-claude-code-integration
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - internal/agent/cli.go
  - internal/agent/evaluator.go
  - internal/agent/prompts.go
  - internal/analyzer/c4_documentation.go
  - internal/agent/evaluator_test.go
autonomous: true

must_haves:
  truths:
    - "CLI detection correctly identifies Claude CLI availability"
    - "Evaluator returns structured JSON scores via CLI"
    - "C4 analyzer produces same metrics using CLI as it did with SDK"
  artifacts:
    - path: "internal/agent/cli.go"
      provides: "CLI detection and version checking"
      exports: ["DetectCLI", "CLIStatus"]
    - path: "internal/agent/evaluator.go"
      provides: "Unified content evaluation via CLI"
      exports: ["Evaluator", "EvaluateContent", "EvaluationResult"]
    - path: "internal/agent/prompts.go"
      provides: "C4 evaluation prompts (migrated from llm package)"
      exports: ["ReadmeClarityPrompt", "ExampleQualityPrompt", "CompletenessPrompt", "CrossRefCoherencePrompt"]
    - path: "internal/analyzer/c4_documentation.go"
      provides: "C4 analyzer using CLI-based evaluator"
      contains: "agent.Evaluator"
  key_links:
    - from: "internal/analyzer/c4_documentation.go"
      to: "internal/agent/evaluator.go"
      via: "agent.Evaluator.EvaluateContent()"
      pattern: "agent\\.Evaluator"
    - from: "internal/agent/evaluator.go"
      to: "claude CLI"
      via: "exec.CommandContext with -p flag"
      pattern: "exec\\.CommandContext.*claude"
---

<objective>
Create CLI-based content evaluation infrastructure for C4 documentation analysis.

Purpose: Replace Anthropic SDK-based evaluation with Claude CLI execution, unifying all LLM features under the CLI.
Output: Working C4 analyzer using Claude CLI for documentation quality evaluation.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/15-claude-code-integration/15-CONTEXT.md
@.planning/phases/15-claude-code-integration/15-RESEARCH.md

# Existing implementation patterns
@internal/agent/executor.go
@internal/llm/client.go
@internal/llm/prompts.go
@internal/analyzer/c4_documentation.go
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create CLI detection module</name>
  <files>internal/agent/cli.go</files>
  <action>
Create `internal/agent/cli.go` with CLI detection and caching:

1. Define `CLIStatus` struct:
   - `Available bool` - whether CLI is usable
   - `Version string` - CLI version string (e.g., "claude 2.1.12")
   - `Error string` - error message if not available
   - `InstallHint string` - installation instructions

2. Implement `DetectCLI() CLIStatus`:
   - Use `exec.LookPath("claude")` to find CLI
   - If not found: return CLIStatus with Available=false, InstallHint with installation URLs
   - If found: run `claude --version` with 5-second timeout
   - Parse version output, return CLIStatus with Available=true and Version

3. Implement `DetectCLIWithContext(ctx context.Context) CLIStatus` for testability

4. Add package-level cached result with sync.Once for efficiency:
   - `var cliStatusOnce sync.Once`
   - `var cachedCLIStatus CLIStatus`
   - `GetCLIStatus() CLIStatus` that populates cache on first call

Install hint should include:
- curl -fsSL https://claude.ai/install.sh | bash
- brew install --cask claude-code
- npm install -g @anthropic-ai/claude-code
  </action>
  <verify>
Create test file `internal/agent/cli_test.go` with:
- `TestDetectCLI_Available` - mock successful detection
- `TestDetectCLI_NotFound` - verify install hint is populated
- Run `go test ./internal/agent/... -run TestDetect`
  </verify>
  <done>CLIStatus struct and DetectCLI function exist, tests pass</done>
</task>

<task type="auto">
  <name>Task 2: Create CLI-based evaluator and migrate prompts</name>
  <files>internal/agent/evaluator.go, internal/agent/prompts.go, internal/agent/evaluator_test.go</files>
  <action>
**Part A: Create `internal/agent/prompts.go`**

Copy C4 evaluation prompts from `internal/llm/prompts.go`:
- ReadmeClarityPrompt
- ExampleQualityPrompt
- CompletenessPrompt
- CrossRefCoherencePrompt
- PromptType enum and GetPrompt function

No changes to prompt text content - exact copy.

**Part B: Create `internal/agent/evaluator.go`**

1. Define `EvaluationResult` struct:
   - `Score int` (1-10)
   - `Reason string`

2. Define `Evaluator` struct:
   - `timeout time.Duration` (default 60s)

3. Implement `NewEvaluator(timeout time.Duration) *Evaluator`

4. Implement `EvaluateContent(ctx context.Context, systemPrompt, content string) (EvaluationResult, error)`:
   - Build JSON schema for structured output:
     ```json
     {"type":"object","properties":{"score":{"type":"integer","minimum":1,"maximum":10},"reason":{"type":"string"}},"required":["score","reason"]}
     ```
   - Build CLI args: `-p`, content, `--system-prompt`, systemPrompt, `--output-format`, `json`, `--json-schema`, schema
   - Create exec.CommandContext with timeout
   - Set cmd.Cancel to send SIGINT (graceful shutdown)
   - Set cmd.WaitDelay to 10 seconds
   - Execute and capture combined output
   - Handle timeout: return error "evaluation timed out after {duration}"
   - Parse JSON response structure:
     ```go
     var resp struct {
         SessionID        string           `json:"session_id"`
         Result           string           `json:"result"`
         StructuredOutput EvaluationResult `json:"structured_output"`
     }
     ```
   - Validate score is 1-10
   - Return StructuredOutput

5. Implement `EvaluateWithRetry(ctx context.Context, systemPrompt, content string) (EvaluationResult, error)`:
   - Try EvaluateContent once
   - On failure, wait 2 seconds, retry once
   - Return error if both attempts fail

Pattern from RESEARCH.md, adapted from existing executor.go.
  </action>
  <verify>
Create `internal/agent/evaluator_test.go` with:
- `TestEvaluator_EvaluateContent` - test with mock CLI (using test helper that sets up command)
- `TestEvaluator_Timeout` - verify timeout handling
- `TestEvaluator_RetryOnFailure` - verify retry logic
Run `go test ./internal/agent/... -run TestEvaluator`
  </verify>
  <done>Evaluator struct with EvaluateContent and EvaluateWithRetry methods exist, prompts migrated, tests pass</done>
</task>

<task type="auto">
  <name>Task 3: Refactor C4 analyzer to use CLI evaluator</name>
  <files>internal/analyzer/c4_documentation.go</files>
  <action>
Refactor `internal/analyzer/c4_documentation.go` to use CLI-based evaluator:

1. Change import from `internal/llm` to `internal/agent`

2. Update C4Analyzer struct:
   - Change `llmClient *llm.Client` to `evaluator *agent.Evaluator`

3. Update SetLLMClient to SetEvaluator:
   - `func (a *C4Analyzer) SetEvaluator(eval *agent.Evaluator)`
   - Set `a.evaluator = eval`

4. Update runLLMAnalysis:
   - Change condition from `if a.llmClient != nil` to `if a.evaluator != nil`
   - Replace `a.llmClient.EvaluateContent(ctx, llm.XxxPrompt, content)` calls with:
     `a.evaluator.EvaluateWithRetry(ctx, agent.XxxPrompt, content)`
   - Update all 4 evaluation calls (ReadmeClarity, ExampleQuality, Completeness, CrossRefCoherence)

5. Update LLMEnabled check in Analyze method:
   - Check `a.evaluator != nil` instead of `a.llmClient != nil`

6. Remove import of `internal/llm` (will cause compile error until plan 02 removes llm usage elsewhere)
   - Keep llm import temporarily if needed for compilation; plan 02 will complete removal

Keep all other C4 logic unchanged (static analysis, file reading, metrics calculation).
  </action>
  <verify>
Run: `go build ./...` - should compile
Run: `go test ./internal/analyzer/... -run TestC4` - existing tests should pass
Manual test: `go run . scan . --json` should work (LLM features disabled until pipeline integration in plan 02)
  </verify>
  <done>C4 analyzer compiles and uses agent.Evaluator, existing tests pass</done>
</task>

</tasks>

<verification>
After all tasks:
1. `go build ./...` compiles without errors
2. `go test ./internal/agent/...` passes with new CLI and Evaluator tests
3. `go test ./internal/analyzer/...` passes (C4 tests)
4. New files exist: cli.go, evaluator.go, prompts.go in internal/agent/
5. C4 analyzer uses agent.Evaluator (grep confirms)
</verification>

<success_criteria>
- CLI detection infrastructure ready (DetectCLI, CLIStatus)
- Evaluator provides CLI-based content evaluation with retry
- C4 prompts migrated to agent package
- C4 analyzer refactored to use CLI evaluator
- All tests pass
- Code compiles cleanly
</success_criteria>

<output>
After completion, create `.planning/phases/15-claude-code-integration/15-01-SUMMARY.md`
</output>
