---
phase: 22-c4-documentation
plan: 01
type: execute
wave: 1
depends_on: []
files_modified: [internal/output/descriptions.go, internal/output/citations.go]
autonomous: true

must_haves:
  truths:
    - "All 7 C4 metrics have inline citations with (Author, Year) format"
    - "C4 References section contains complete citations with verified URLs"
    - "Every quantified claim in C4 descriptions has explicit attribution"
    - "Citation density follows 2-3 per metric guideline"
  artifacts:
    - path: "internal/output/descriptions.go"
      provides: "C4 metric descriptions with inline citations"
      contains: "Prana et al., 2019"
    - path: "internal/output/citations.go"
      provides: "C4 reference entries"
      contains: "Categorizing the Content of GitHub README Files"
  key_links:
    - from: "descriptions.go readme_word_count"
      to: "citations.go C4 Prana entry"
      via: "matching Author, Year format"
      pattern: "Prana.*2019"
    - from: "descriptions.go api_doc_coverage"
      to: "citations.go C4 Robillard 2011 entry"
      via: "matching Author, Year format"
      pattern: "Robillard.*2011"
---

<objective>
Add research-backed citations to all 7 C4 Documentation metrics following established quality protocols from Phase 18.

Purpose: Complete C4 with scientific foundations, continuing the citation pattern established in C1, C2, C3, and C6 phases. Documentation research spans API learning obstacles (Robillard), README empirical studies (Prana et al.), and comment quality (Rani et al.).
Output: Updated descriptions.go with inline citations for all C4 metrics, expanded citations.go with additional C4 reference entries.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/22-c4-documentation/22-RESEARCH.md
@.planning/phases/21-c3-architecture/21-01-SUMMARY.md
@internal/output/descriptions.go
@internal/output/citations.go
</context>

<tasks>

<task type="auto">
  <name>Task 1: Update C4 metric descriptions with inline citations</name>
  <files>internal/output/descriptions.go</files>
  <action>
Update all 7 C4 metric descriptions following the pattern established in prior phases (18-02, 19-01, 20-01, 21-01):

**readme_word_count:**
- Brief: Add Prana et al. (2019) citation for README content research
- Detailed: Add Research Evidence section citing:
  - Prana et al. (2019) for empirical study of 4,226 README sections identifying 8 content categories
  - Wang et al. (2023) for README organization correlating with project popularity
  - Borg et al. (2026) for AI agent comprehension of well-documented code

**comment_density:**
- Brief: Add Rani et al. (2022) citation for comment quality research
- Detailed: Add Research Evidence section citing:
  - Knuth (1984) for literate programming foundations
  - Rani et al. (2022) for systematic review of 21 comment quality attributes
  - Wen et al. (2019) for code-comment inconsistency taxonomy
  - Borg et al. (2026) for AI agent comprehension

**api_doc_coverage:**
- Brief: Add Robillard (2011) citation for API learning obstacles
- Detailed: Add Research Evidence section citing:
  - Robillard (2011) for API learning obstacles study with 440+ developers
  - Uddin & Robillard (2015) for systematic analysis showing ambiguity, incompleteness, incorrectness as top problems
  - Garousi et al. (2013) for documentation quality varying by task type
  - Borg et al. (2026) for AI agent reliability

**changelog_present:**
- Brief: Add Abebe et al. (2016) citation for release notes research
- Detailed: Add Research Evidence section citing:
  - Abebe et al. (2016) for empirical study of release note content types
  - Borg et al. (2026) for AI agent comprehension
  - Note: Changelog-specific research is sparse; Abebe et al. covers release notes as closest proxy

**examples_present:**
- Brief: Add Robillard (2011) citation for example importance in API learning
- Detailed: Add Research Evidence section citing:
  - Robillard (2011) for examples as critical factor in API learning
  - Sohan et al. (2017) for examples reducing mistakes and improving success rate
  - Uddin & Robillard (2015) for examples as critical design factor
  - Borg et al. (2026) for AI agent reliability

**contributing_present:**
- Brief: Add Prana et al. (2019) citation for contribution guidelines as README category
- Detailed: Add Research Evidence section citing:
  - Prana et al. (2019) for contribution guidelines as one of 8 README content categories
  - Borg et al. (2026) for AI agent comprehension
  - Note: Contributing file research is emerging; research covers guidelines within READMEs

**diagrams_present:**
- Brief: Keep Gamma et al. (1994) citation for visual notation in design patterns
- Detailed: Add Research Evidence section citing:
  - Gamma et al. (1994) for visual notation aiding comprehension of object-oriented designs
  - Borg et al. (2026) for AI agent comprehension
  - Note: Diagram effectiveness for AI agents is indirect since agents primarily process text

Use `<span class="citation">(Author, Year)</span>` format for all inline citations.
Each metric should have at least 1 foundational (pre-2021) and 1 AI-era source.
  </action>
  <verify>
Run: `grep -c "citation" internal/output/descriptions.go | head -1`
Confirm: Citation count increased from baseline
Run: `grep -E "readme_word_count|comment_density|api_doc_coverage|changelog_present|examples_present|contributing_present|diagrams_present" internal/output/descriptions.go | grep -c citation`
Confirm: Each C4 metric has inline citations visible
Run: `go build ./...` passes
  </verify>
  <done>All 7 C4 metrics have inline citations with Research Evidence sections following established pattern</done>
</task>

<task type="auto">
  <name>Task 2: Add C4 reference entries to citations.go</name>
  <files>internal/output/citations.go</files>
  <action>
Expand C4 section in researchCitations slice. Keep existing Sadowski et al. (2015) and Robillard (2009) entries, add:

```go
// Add after existing C4 entries
{
    Category:    "C4",
    Title:       "Categorizing the Content of GitHub README Files",
    Authors:     "Prana et al.",
    Year:        2019,
    URL:         "https://doi.org/10.1007/s10664-018-9660-3",
    Description: "Empirical study of 4,226 README sections; identified 8 content categories with classifier F1=0.746",
},
{
    Category:    "C4",
    Title:       "Study the Correlation between the README File of GitHub Projects and Their Popularity",
    Authors:     "Wang et al.",
    Year:        2023,
    URL:         "https://doi.org/10.1016/j.jss.2023.111806",
    Description: "README organization and update frequency correlate with project popularity",
},
{
    Category:    "C4",
    Title:       "A field study of API learning obstacles",
    Authors:     "Robillard",
    Year:        2011,
    URL:         "https://doi.org/10.1007/s10664-010-9150-8",
    Description: "Documentation obstacles among most severe for API learning; 440+ developers surveyed",
},
{
    Category:    "C4",
    Title:       "How API Documentation Fails",
    Authors:     "Uddin & Robillard",
    Year:        2015,
    URL:         "https://doi.org/10.1109/MS.2014.80",
    Description: "Top problems: ambiguity, incompleteness, incorrectness; 6 of 10 problems are blockers",
},
{
    Category:    "C4",
    Title:       "Evaluating usage and quality of technical software documentation",
    Authors:     "Garousi et al.",
    Year:        2013,
    URL:         "https://doi.org/10.1145/2460999.2461003",
    Description: "Documentation often outdated, incomplete; usage differs by task type",
},
{
    Category:    "C4",
    Title:       "A Decade of Code Comment Quality Assessment: A Systematic Literature Review",
    Authors:     "Rani et al.",
    Year:        2022,
    URL:         "https://doi.org/10.1016/j.jss.2022.111515",
    Description: "Systematic review: 21 quality attributes; consistency between comments and code predominant",
},
{
    Category:    "C4",
    Title:       "A Large-Scale Empirical Study on Code-Comment Inconsistencies",
    Authors:     "Wen et al.",
    Year:        2019,
    URL:         "https://doi.org/10.1109/ICPC.2019.00019",
    Description: "Analyzed 1.3B AST changes; taxonomy of 13 code-comment inconsistency types",
},
{
    Category:    "C4",
    Title:       "Literate Programming",
    Authors:     "Knuth",
    Year:        1984,
    URL:         "https://doi.org/10.1093/comjnl/27.2.97",
    Description: "Programs should be written for humans to read, secondarily for machines to execute",
},
{
    Category:    "C4",
    Title:       "An empirical study of software release notes",
    Authors:     "Abebe et al.",
    Year:        2016,
    URL:         "https://doi.org/10.1007/s10664-015-9377-5",
    Description: "6 types of release note content; content varies between systems and versions",
},
{
    Category:    "C4",
    Title:       "A study of the effectiveness of usage examples in REST API documentation",
    Authors:     "Sohan et al.",
    Year:        2017,
    URL:         "https://ieeexplore.ieee.org/document/8103450",
    Description: "Examples reduce mistakes, improve success rate and developer satisfaction",
},
{
    Category:    "C4",
    Title:       "Design Patterns: Elements of Reusable Object-Oriented Software",
    Authors:     "Gamma et al.",
    Year:        1994,
    URL:         "https://en.wikipedia.org/wiki/Design_Patterns",
    Description: "Visual notation aids comprehension of object-oriented designs",
},
{
    Category:    "C4",
    Title:       "Code for Machines, Not Just Humans: Quantifying AI-Friendliness with Code Health Metrics",
    Authors:     "Borg et al.",
    Year:        2026,
    URL:         "https://arxiv.org/abs/2601.02200",
    Description: "Code health metrics including documentation predict AI agent reliability",
},
```

Note: Gamma et al. (1994) and Borg et al. (2026) exist in other category sections - add as C4 entries for category self-containment (same pattern as prior phases).
  </action>
  <verify>
Run: `grep -c "Category.*C4" internal/output/citations.go`
Confirm: At least 14 C4 citation entries (existing 2 + 12 new)
Run: `go build ./...` passes
  </verify>
  <done>C4 References section contains 14 entries covering foundational documentation research, empirical studies, and AI-era sources</done>
</task>

<task type="auto">
  <name>Task 3: Verify all C4 citation URLs are accessible</name>
  <files></files>
  <action>
Verify each C4 citation URL is accessible using curl with browser User-Agent (to bypass bot protection):

URLs to verify:
1. Sadowski et al. (2015): https://dl.acm.org/doi/10.1145/2786805.2786855
2. Robillard (2009): https://ieeexplore.ieee.org/document/5070510
3. Prana et al. (2019): https://doi.org/10.1007/s10664-018-9660-3
4. Wang et al. (2023): https://doi.org/10.1016/j.jss.2023.111806
5. Robillard (2011): https://doi.org/10.1007/s10664-010-9150-8
6. Uddin & Robillard (2015): https://doi.org/10.1109/MS.2014.80
7. Garousi et al. (2013): https://doi.org/10.1145/2460999.2461003
8. Rani et al. (2022): https://doi.org/10.1016/j.jss.2022.111515
9. Wen et al. (2019): https://doi.org/10.1109/ICPC.2019.00019
10. Knuth (1984): https://doi.org/10.1093/comjnl/27.2.97
11. Abebe et al. (2016): https://doi.org/10.1007/s10664-015-9377-5
12. Sohan et al. (2017): https://ieeexplore.ieee.org/document/8103450
13. Gamma et al. (1994): https://en.wikipedia.org/wiki/Design_Patterns
14. Borg et al. (2026): https://arxiv.org/abs/2601.02200

Use: `curl -I -A "Mozilla/5.0" [URL]` to check HTTP status
For DOI URLs: Verify they resolve (302/301 redirect is success)
For ACM/IEEE: DOI format is permanent, 403 bot protection is expected for automated requests

Document any issues found. If a URL is inaccessible, find alternative (DOI preferred, then open-access version).
  </action>
  <verify>
All 14 URLs return HTTP 200 or 3xx redirect (DOI resolution)
No broken links
  </verify>
  <done>All C4 citation URLs verified accessible or DOI resolution confirmed</done>
</task>

</tasks>

<verification>
1. `go build ./...` passes
2. `go test ./internal/output/...` passes (if tests exist)
3. All 7 C4 metrics in descriptions.go have inline citations
4. At least 14 C4 entries in citations.go
5. All URLs verified accessible
</verification>

<success_criteria>
- All 7 C4 metrics have inline citations referencing documentation quality research
- C4 References section contains 14 complete citations with verified, accessible URLs
- Open-access versions provided for paywalled sources where possible
- Every quantified claim in C4 metric descriptions has explicit source attribution
</success_criteria>

<output>
After completion, create `.planning/phases/22-c4-documentation/22-01-SUMMARY.md`
</output>
