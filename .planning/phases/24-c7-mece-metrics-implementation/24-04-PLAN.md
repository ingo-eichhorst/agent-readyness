---
phase: 24-c7-mece-metrics-implementation
plan: 04
type: execute
wave: 2
depends_on: ["24-01"]
files_modified:
  - pkg/types/types.go
  - internal/scoring/config.go
autonomous: true

must_haves:
  truths:
    - "C7Metrics type includes all 5 MECE metric scores"
    - "Scoring config has breakpoints for all 5 C7 metrics"
    - "Backward compatibility maintained - existing fields preserved"
    - "Each metric has research-based scoring thresholds"
  artifacts:
    - path: "pkg/types/types.go"
      provides: "Updated C7Metrics with 5 metric fields"
      contains: "TaskExecutionConsistency"
    - path: "internal/scoring/config.go"
      provides: "C7 category with 5 metric thresholds"
      contains: "task_execution_consistency"
  key_links:
    - from: "internal/scoring/config.go"
      to: "C7 metrics"
      via: "MetricThresholds entries"
      pattern: "task_execution_consistency|code_behavior_comprehension|cross_file_navigation"
---

<objective>
Update types and scoring configuration for the 5 MECE C7 metrics.

Purpose: Enable scoring of individual C7 metrics with research-based thresholds, and update the C7Metrics type to store results for all 5 metrics.

Output: Updated pkg/types/types.go with new C7 fields, updated internal/scoring/config.go with 5 metric breakpoints.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/24-c7-mece-metrics-implementation/24-CONTEXT.md
@.planning/phases/24-c7-mece-metrics-implementation/24-RESEARCH.md
@.planning/phases/24-c7-mece-metrics-implementation/24-01-SUMMARY.md

# Files to modify
@pkg/types/types.go
@internal/scoring/config.go
</context>

<tasks>

<task type="auto">
  <name>Task 1: Update C7Metrics type with 5 new metric fields</name>
  <files>pkg/types/types.go</files>
  <action>
Update the C7Metrics struct in pkg/types/types.go to include the 5 MECE metrics while preserving backward compatibility.

Find the existing C7Metrics struct (around line 254) and update it:

```go
// C7Metrics holds agent evaluation results including 5 MECE metrics.
type C7Metrics struct {
    Available bool // false if claude CLI not found or user declined

    // Legacy 4-task scores (0-100 scale) - preserved for backward compatibility
    IntentClarity          int // 0-100 score
    ModificationConfidence int // 0-100 score
    CrossFileCoherence     int // 0-100 score
    SemanticCompleteness   int // 0-100 score

    // NEW: 5 MECE metrics (1-10 scale)
    TaskExecutionConsistency     int // M1: Reproducibility across runs (1-10)
    CodeBehaviorComprehension    int // M2: Understanding what code does (1-10)
    CrossFileNavigation          int // M3: Tracing dependencies across files (1-10)
    IdentifierInterpretability   int // M4: Inferring meaning from names (1-10)
    DocumentationAccuracyDetection int // M5: Detecting comment/code mismatches (1-10)

    // Aggregate scores
    OverallScore float64 // Legacy: average of 4 task scores (0-100)
    MECEScore    float64 // NEW: weighted average of 5 MECE metrics (1-10)

    // Detailed results
    TaskResults   []C7TaskResult   // Legacy task results
    MetricResults []C7MetricResult // NEW: MECE metric results

    // Execution metadata
    TotalDuration float64 // seconds
    TokensUsed    int     // estimated total tokens
    CostUSD       float64 // estimated cost
}

// C7MetricResult holds results for a single MECE metric.
type C7MetricResult struct {
    MetricID   string   // e.g., "task_execution_consistency"
    MetricName string   // e.g., "Task Execution Consistency"
    Score      int      // 1-10
    Status     string   // completed, timeout, error
    Duration   float64  // seconds
    Reasoning  string   // scoring rationale
    Samples    []string // sample descriptions used
}
```

Important:
- Keep ALL existing fields for backward compatibility
- Add new fields alongside, don't remove anything
- New MECE metrics use 1-10 scale (matches C1-C6)
- Legacy fields use 0-100 scale (preserved)
  </action>
  <verify>
File updated: `grep "TaskExecutionConsistency" pkg/types/types.go`
Has all 5 metrics: `grep -c "int // M[1-5]:" pkg/types/types.go` should be 5
Has MECEScore: `grep "MECEScore" pkg/types/types.go`
Has C7MetricResult: `grep "type C7MetricResult struct" pkg/types/types.go`
Backward compat: `grep "IntentClarity" pkg/types/types.go`
  </verify>
  <done>
C7Metrics updated with 5 new MECE metric fields (1-10 scale), MECEScore aggregate, C7MetricResult type for detailed results. All legacy fields preserved for backward compatibility.
  </done>
</task>

<task type="auto">
  <name>Task 2: Update C7 scoring config with 5 metric breakpoints</name>
  <files>internal/scoring/config.go</files>
  <action>
Update the C7 category in DefaultConfig() (around line 443) to include breakpoints for all 5 MECE metrics.

Replace the existing C7 config:

```go
"C7": {
    Name:   "Agent Evaluation",
    Weight: 0.10,
    Metrics: []MetricThresholds{
        // Legacy overall_score preserved for backward compatibility
        {
            Name:   "overall_score",
            Weight: 0.0, // Zero weight - not used in new scoring
            Breakpoints: []Breakpoint{
                {Value: 0, Score: 1},
                {Value: 30, Score: 3},
                {Value: 50, Score: 5},
                {Value: 70, Score: 7},
                {Value: 90, Score: 10},
            },
        },
        // M1: Task Execution Consistency
        // Measures reproducibility across runs
        // Research: Agent benchmarks show ~13% variance is typical
        {
            Name:   "task_execution_consistency",
            Weight: 0.20,
            Breakpoints: []Breakpoint{
                {Value: 1, Score: 1},  // >30% variance
                {Value: 4, Score: 4},  // 15-30% variance
                {Value: 7, Score: 7},  // 5-15% variance
                {Value: 10, Score: 10}, // <5% variance
            },
        },
        // M2: Code Behavior Comprehension
        // Measures understanding of code semantics (not syntax)
        // Research: LLMs struggle with semantic vs syntactic understanding
        {
            Name:   "code_behavior_comprehension",
            Weight: 0.25,
            Breakpoints: []Breakpoint{
                {Value: 1, Score: 1},  // Fundamentally wrong
                {Value: 4, Score: 4},  // Partial understanding
                {Value: 7, Score: 7},  // Correct main path
                {Value: 10, Score: 10}, // All paths including edge cases
            },
        },
        // M3: Cross-File Navigation
        // Measures dependency tracing across files
        // Research: RepoGraph shows 32.8% improvement with repo-level understanding
        {
            Name:   "cross_file_navigation",
            Weight: 0.25,
            Breakpoints: []Breakpoint{
                {Value: 1, Score: 1},  // Single file only
                {Value: 4, Score: 4},  // Direct dependencies
                {Value: 7, Score: 7},  // Most of chain
                {Value: 10, Score: 10}, // Complete trace
            },
        },
        // M4: Identifier Interpretability
        // Measures ability to infer meaning from names
        // Research: Descriptive compound identifiers improve comprehension
        {
            Name:   "identifier_interpretability",
            Weight: 0.15,
            Breakpoints: []Breakpoint{
                {Value: 1, Score: 1},  // Misinterprets
                {Value: 4, Score: 4},  // Needs context
                {Value: 7, Score: 7},  // Mostly correct
                {Value: 10, Score: 10}, // Correct interpretation
            },
        },
        // M5: Documentation Accuracy Detection
        // Measures ability to detect comment/code mismatches
        // Research: CCI detection is a distinct, measurable capability
        {
            Name:   "documentation_accuracy_detection",
            Weight: 0.15,
            Breakpoints: []Breakpoint{
                {Value: 1, Score: 1},  // Cannot detect
                {Value: 4, Score: 4},  // Obvious only
                {Value: 7, Score: 7},  // Most mismatches
                {Value: 10, Score: 10}, // All mismatches
            },
        },
    },
},
```

Weight rationale (from research):
- M1 (20%): Consistency is important but less impactful than comprehension
- M2 (25%): Code comprehension is critical for agent success (SWE-bench)
- M3 (25%): Cross-file navigation correlates strongly with task completion (RepoGraph)
- M4 (15%): Identifier interpretation helps but is less critical
- M5 (15%): Documentation detection is useful but not primary

Weights sum to 1.0 (excluding legacy overall_score at 0.0).
  </action>
  <verify>
Has all 5 metrics: `grep -c "task_execution_consistency\|code_behavior_comprehension\|cross_file_navigation\|identifier_interpretability\|documentation_accuracy_detection" internal/scoring/config.go` should be 5
Weights sum to 1.0: Check that 0.20 + 0.25 + 0.25 + 0.15 + 0.15 = 1.0
Legacy preserved: `grep "overall_score" internal/scoring/config.go`
Compiles: `go build ./internal/scoring/...`
  </verify>
  <done>
C7 scoring config updated with 5 metric breakpoints, research-based weights (M2/M3 highest at 25% each), and legacy overall_score preserved with zero weight for backward compatibility.
  </done>
</task>

</tasks>

<verification>
```bash
# Types compile
go build ./pkg/types/...

# Scoring compiles
go build ./internal/scoring/...

# C7Metrics has new fields
grep -E "TaskExecutionConsistency|CodeBehaviorComprehension|CrossFileNavigation|IdentifierInterpretability|DocumentationAccuracyDetection" pkg/types/types.go

# Scoring config has new metrics
grep -E "task_execution_consistency|code_behavior_comprehension|cross_file_navigation" internal/scoring/config.go

# C7MetricResult type exists
grep "type C7MetricResult struct" pkg/types/types.go

# Full build passes
go build ./...
```
</verification>

<success_criteria>
- C7Metrics has 5 new MECE metric fields (TaskExecutionConsistency through DocumentationAccuracyDetection)
- C7MetricResult type exists for detailed metric results
- Scoring config has breakpoints for all 5 C7 metrics with weights summing to 1.0
- Legacy fields (IntentClarity, etc.) preserved
- All packages compile: `go build ./...` succeeds
</success_criteria>

<output>
After completion, create `.planning/phases/24-c7-mece-metrics-implementation/24-04-SUMMARY.md`
</output>
