---
phase: 30-evidence-data-flow
plan: 02
type: execute
wave: 2
depends_on: ["30-01"]
files_modified:
  - internal/scoring/scorer.go
autonomous: true

must_haves:
  truths:
    - "extractC1 returns top-5 worst offenders for complexity_avg, func_length_avg, duplication_rate, and coupling metrics"
    - "extractC3 returns evidence for circular_deps and dead_exports metrics"
    - "extractC5 returns evidence from TopHotspots and CoupledPairs"
    - "extractC6 returns evidence for test_isolation and assertion_density_avg"
    - "C2, C4, C7 extractors return empty evidence arrays (aggregate-only or per CONTEXT decision)"
    - "All evidence arrays are non-nil (empty []EvidenceItem{} not nil)"
  artifacts:
    - path: "internal/scoring/scorer.go"
      provides: "All 7 extractCx functions with evidence population"
  key_links:
    - from: "internal/scoring/scorer.go"
      to: "pkg/types/types.go"
      via: "Reads CxMetrics per-item data (Functions, DeadExports, TopHotspots, etc.)"
      pattern: "sort\\.Slice"
---

<objective>
Populate real evidence data in all 7 extractCx functions by extracting top-5 worst offenders from existing CxMetrics data structures.

Purpose: This is the core evidence extraction work. After this plan, every scored metric carries its worst offenders through the pipeline, ready for JSON output and downstream modal rendering.

Output: All extractCx functions return meaningful evidence maps. Metrics with per-item data return sorted top-5 offenders. Aggregate-only metrics return empty arrays.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/30-evidence-data-flow/30-CONTEXT.md
@.planning/phases/30-evidence-data-flow/30-RESEARCH.md
@.planning/phases/30-evidence-data-flow/30-01-SUMMARY.md
@internal/scoring/scorer.go
@pkg/types/types.go
</context>

<tasks>

<task type="auto">
  <name>Task 1: Populate evidence in extractC1, extractC3, extractC5, extractC6</name>
  <files>internal/scoring/scorer.go</files>
  <action>
  Add `"fmt"` and `"sort"` to the import block of scorer.go (if not already present).

  **extractC1 (6 metrics, rich per-item data):**

  Create evidence map after successful type assertion. For each metric:

  - `complexity_avg`: Sort `m.Functions` (copy first) by `.Complexity` descending, take top 5. Description: `fmt.Sprintf("%s has complexity %d", f.Name, f.Complexity)`. FilePath: f.File, Line: f.Line, Value: float64(f.Complexity).
  - `func_length_avg`: Sort `m.Functions` (copy first) by `.LineCount` descending, take top 5. Description: `fmt.Sprintf("%s is %d lines", f.Name, f.LineCount)`. FilePath: f.File, Line: f.Line, Value: float64(f.LineCount).
  - `file_size_avg`: Use `m.FileSize.MaxEntity` as single evidence item if non-empty. FilePath: m.FileSize.MaxEntity, Line: 0, Value: m.FileSize.Max, Description: fmt.Sprintf("largest file: %d lines", int(m.FileSize.Max)).
  - `afferent_coupling_avg`: Sort `m.AfferentCoupling` map entries by value descending, take top 5. FilePath: package name (the map key), Line: 0, Value: float64(coupling count), Description: fmt.Sprintf("imported by %d packages", count).
  - `efferent_coupling_avg`: Same pattern as afferent, with Description: fmt.Sprintf("imports %d packages", count).
  - `duplication_rate`: Sort `m.DuplicatedBlocks` by `.LineCount` descending, take top 5. FilePath: block.File (or first file), Line: block.StartLine, Value: float64(block.LineCount), Description: fmt.Sprintf("%d-line duplicate block", block.LineCount). Check the DuplicateBlock struct fields first -- if File/StartLine don't exist, use what's available.

  After populating, ensure ALL 6 metric keys have at least `[]types.EvidenceItem{}` (iterate over metric names, set empty if nil).

  **extractC3 (5 metrics, mixed data):**

  - `max_dir_depth`: Use `m.MaxDirectoryDepth` value. If MaxEntity available on the MetricSummary, single evidence item. Otherwise empty array.
  - `module_fanout_avg`: Use `m.ModuleFanout.MaxEntity` if available as single item. Otherwise empty.
  - `circular_deps`: Take first 5 entries from `m.CircularDeps [][]string`. For each cycle, FilePath: first element, Line: 0, Value: float64(len(cycle)), Description: fmt.Sprintf("cycle: %s", strings.Join(cycle, " -> ")).
  - `import_complexity_avg`: Use `m.ImportComplexity.MaxEntity` if available. Otherwise empty.
  - `dead_exports`: Sort `m.DeadExports` (already a list), take first 5. FilePath: export.File, Line: export.Line, Value: 1, Description: fmt.Sprintf("unused %s: %s", export.Kind, export.Name). Check DeadExport struct fields.

  Ensure all 5 keys have at least empty arrays.

  **extractC5 (5 metrics, git-based data):**

  When `!m.Available`, return empty evidence map (same early return path, just add the third nil return).

  When available:
  - `churn_rate`: Use `m.TopHotspots` (already sorted by churn). Take top 5. FilePath: hotspot.Path, Line: 0, Value: float64(hotspot.Commits or hotspot.Changes), Description: fmt.Sprintf("%d commits", hotspot.Commits). Check FileChurn struct fields.
  - `temporal_coupling_pct`: Take first 5 from `m.CoupledPairs`. FilePath: pair.FileA, Line: 0, Value: pair.CouplingPct or pair.Confidence, Description: fmt.Sprintf("coupled with %s (%.0f%%)", pair.FileB, pair.CouplingPct). Check CoupledPair struct.
  - `author_fragmentation`: Use TopHotspots sorted by author count if available. Otherwise empty.
  - `commit_stability`: Empty array (no per-file stability stored).
  - `hotspot_concentration`: Use `m.TopHotspots` directly (already sorted). Take top 5. Same as churn_rate items but with different description: fmt.Sprintf("hotspot: %d changes", changes).

  Ensure all 5 keys have at least empty arrays.

  **extractC6 (5 metrics, per-test data):**

  - `test_to_code_ratio`: Empty array (global metric).
  - `coverage_percent`: Empty array (no per-file coverage in struct).
  - `test_isolation`: Filter `m.TestFunctions` for those with `HasExternalDep == true`, take top 5. FilePath: tf.File, Line: tf.Line, Value: 1, Description: fmt.Sprintf("%s has external dependency", tf.Name). Check TestFunctionMetric struct fields.
  - `assertion_density_avg`: Sort `m.TestFunctions` (copy first) by `.AssertionCount` ascending (lowest = worst), take top 5 that have AssertionCount >= 0. FilePath: tf.File, Line: tf.Line, Value: float64(tf.AssertionCount), Description: fmt.Sprintf("%s has %d assertions", tf.Name, tf.AssertionCount).
  - `test_file_ratio`: Empty array (global metric).

  Ensure all 5 keys have at least empty arrays.

  **IMPORTANT:** Before writing evidence extraction, read the actual CxMetrics struct definitions in `pkg/types/types.go` to confirm exact field names. The research doc may have slight naming differences. Use the ACTUAL field names from the code.

  **Pattern for sorting and top-5 selection:**
  ```go
  sorted := make([]types.FunctionMetric, len(m.Functions))
  copy(sorted, m.Functions)
  sort.Slice(sorted, func(i, j int) bool {
      return sorted[i].Complexity > sorted[j].Complexity
  })
  limit := 5
  if len(sorted) < limit {
      limit = len(sorted)
  }
  ```

  **Pattern for ensuring non-nil arrays:**
  ```go
  for _, key := range []string{"metric_a", "metric_b", ...} {
      if evidence[key] == nil {
          evidence[key] = []types.EvidenceItem{}
      }
  }
  ```
  </action>
  <verify>Run `go build ./...` -- compiles. Run `go test ./internal/scoring/... -v` -- all tests pass. Run `go test ./...` -- full suite passes.</verify>
  <done>extractC1 returns evidence for all 6 metrics (top-5 functions by complexity, length; top-5 coupling packages; top-5 duplicate blocks; single worst file). extractC3 returns evidence for circular_deps and dead_exports. extractC5 returns evidence from TopHotspots and CoupledPairs. extractC6 returns evidence for test_isolation and assertion_density. C2, C4, C7 return all-empty evidence maps. Every metric key has a non-nil evidence array.</done>
</task>

<task type="auto">
  <name>Task 2: Populate evidence in extractC2, extractC4, extractC7 (empty arrays)</name>
  <files>internal/scoring/scorer.go</files>
  <action>
  These three extractors return only empty evidence arrays per the research and CONTEXT decisions:

  **extractC2 (5 metrics, all aggregate):**
  Create `evidence := make(map[string][]types.EvidenceItem)` after successful type assertion. Set all 5 metric keys to `[]types.EvidenceItem{}`. Return evidence as third value.

  **extractC4 (7 metrics, all aggregate/boolean):**
  Same pattern. Create evidence map, set all 7 metric keys to `[]types.EvidenceItem{}`. Return as third value.

  **extractC7 (5 MECE metrics, per CONTEXT decision):**
  Create evidence map, set all 5 MECE metric keys to `[]types.EvidenceItem{}`. Return as third value. (C7 trace data comes from C7DebugSample in Phase 32, not from evidence arrays.)

  Note: If Task 1 already created stub evidence maps for these (from Plan 01), then Task 2 just confirms they are correct. The key is that all metric keys are explicitly set to empty arrays, not left as nil.
  </action>
  <verify>Run `go test ./internal/scoring/... -v` -- all pass. Manually verify: `grep -c 'EvidenceItem{}' internal/scoring/scorer.go` shows entries for C2, C4, C7.</verify>
  <done>extractC2, extractC4, extractC7 all return evidence maps with explicit empty arrays for every metric key. No nil values anywhere in evidence maps.</done>
</task>

</tasks>

<verification>
1. `go test ./...` passes
2. Add a temporary test or use debugger: create a C1 AnalysisResult with Functions data, call extractC1, verify evidence["complexity_avg"] has items sorted by complexity descending
3. Verify non-nil: no evidence map value is nil (all are empty arrays or populated arrays)
</verification>

<success_criteria>
- All 7 extractCx functions return populated evidence maps
- C1: 6 metrics with evidence from Functions, coupling maps, DuplicatedBlocks
- C3: circular_deps and dead_exports have evidence, others empty
- C5: churn_rate, temporal_coupling_pct, hotspot_concentration have evidence from git data
- C6: test_isolation and assertion_density_avg have evidence from TestFunctions
- C2, C4, C7: all metrics return empty evidence arrays
- Every metric key in every evidence map is non-nil
- `go test ./...` passes with zero failures
</success_criteria>

<output>
After completion, create `.planning/phases/30-evidence-data-flow/30-02-SUMMARY.md`
</output>
