---
phase: 34-testing-and-quality
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - internal/scoring/scorer_test.go
  - internal/output/json_test.go
autonomous: true

must_haves:
  truths:
    - "Evidence extraction tests verify non-empty evidence for all 7 categories when violations exist"
    - "Evidence arrays are always [] not nil for metrics without violations"
    - "C7 returns non-nil evidence map; evidence may be empty for score-based metrics"
    - "C4/C5 binary metrics explicitly verified to return empty arrays (not nil)"
    - "JSON backward compatibility test confirms v1 JSON loads without error"
  artifacts:
    - path: "internal/scoring/scorer_test.go"
      provides: "Evidence extraction tests for C1-C7"
      contains: "TestExtractEvidence"
    - path: "internal/output/json_test.go"
      provides: "Enhanced backward compatibility test"
      contains: "TestJSONBaselineV1"
  key_links:
    - from: "internal/scoring/scorer_test.go"
      to: "internal/scoring/scorer.go"
      via: "extractC1..extractC7 function calls"
      pattern: "extractC[1-7]"
---

<objective>
Add evidence extraction tests for all 7 categories and enhance JSON schema backward compatibility testing.

Purpose: Validate that the evidence data flow (Phase 30) correctly populates non-empty evidence for all metric categories when violations exist, and that v0.0.5-era JSON still loads correctly in the current schema.
Output: New test functions in scorer_test.go and json_test.go
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/34-testing-and-quality/34-RESEARCH.md

@internal/scoring/scorer.go
@internal/scoring/scorer_test.go
@internal/scoring/config.go
@internal/output/json.go
@internal/output/json_test.go
@pkg/types/types.go
</context>

<tasks>

<task type="auto">
  <name>Task 1: Evidence extraction tests for all 7 categories</name>
  <files>internal/scoring/scorer_test.go</files>
  <action>
Add a table-driven test `TestExtractEvidence_AllCategories` with exactly 7 subtests, one per category (C1 through C7). Each subtest must:

1. Construct a synthetic `types.AnalysisResult` with the category's `*Metrics` struct populated with data that would produce evidence (e.g., high-complexity functions for C1, deep directories for C3, low coverage for C6).

2. Call the corresponding `extractCx` function directly and verify ALL of the following:
   - The returned evidence map is not nil (`assert evidence != nil`)
   - For metrics that have file-level violations in the synthetic data, at least one metric key has non-empty evidence (`len(items) > 0`)
   - Each EvidenceItem in non-empty evidence has non-empty FilePath and Description fields
   - Evidence arrays for metrics WITHOUT violations are `[]types.EvidenceItem{}` (empty slice, not nil) -- use `assert.NotNil` on the slice itself

3. For C4 and C5 specifically: binary/boolean metrics like `changelog_present` or `has_readme` produce empty evidence arrays (no file-level violations). The test MUST explicitly verify these metrics return empty slices (`len == 0`) that are NOT nil. This validates the "evidence arrays are always [] not nil" invariant.

4. For C7 specifically: C7 is score-based with no file-level evidence. The test MUST verify:
   - The evidence map returned by extractC7 is non-nil
   - The map contains keys for each C7 metric
   - Each value is a non-nil slice (may be empty `[]EvidenceItem{}`)
   This confirms C7 participates in the evidence system even without file-level data.

Use the existing test helpers (e.g., `makeHealthyC1()`) as reference for constructing AnalysisResults, but modify values to ensure violations exist (e.g., set complexity to 30, function length to 100).

Important: Look at the actual extractCx function signatures in scorer.go to understand what types they accept and return. The evidence is the third return value from these functions.
  </action>
  <verify>Run `go test ./internal/scoring/ -run TestExtractEvidence -v` -- all 7 subtests pass (C1 through C7)</verify>
  <done>
- 7 subtests exist, one per category (C1-C7), each calling the corresponding extractCx function
- All extractCx functions return non-nil evidence maps
- C1-C3, C6 subtests verify at least one metric has non-empty evidence with valid FilePath and Description
- C4/C5 subtests explicitly verify binary metrics return empty slices (len==0, not nil)
- C7 subtest verifies non-nil map with metric keys present, each value a non-nil (possibly empty) slice
- All evidence arrays are [] not nil (the invariant)
  </done>
</task>

<task type="auto">
  <name>Task 2: Enhanced JSON backward compatibility test</name>
  <files>internal/output/json_test.go</files>
  <action>
The existing `TestJSONBaselineBackwardCompatibility` test in json_test.go already covers the basic v1 JSON backward compatibility scenario. Enhance it or add a companion test `TestJSONBaselineV1FullRoundTrip` that:

1. Constructs a more complete v1-era JSON string with all 7 categories (C1-C7), each with at least one metric using the old "metrics" field name
2. Verifies `json.Unmarshal` succeeds without error
3. Verifies all category-level fields load correctly (name, score, weight)
4. Verifies composite_score and tier load correctly
5. Verifies that the code does NOT crash when accessing Categories that had "metrics" (old field name) instead of "sub_scores" (new field name)
6. Adds a test that marshals a current v2 JSONReport and verifies it uses "sub_scores" not "metrics"

Check the existing test first -- if it already covers these cases adequately, skip adding duplicate tests. Only add what is genuinely missing.

Note: The existing test already notes that SubScores will be empty when reading old "metrics" JSON because the tag changed. This is expected behavior since baseline loading only reads category-level scores.
  </action>
  <verify>Run `go test ./internal/output/ -run TestJSONBaseline -v` -- all tests pass</verify>
  <done>JSON backward compatibility test validates v1 JSON loads all category-level fields correctly; no crash on old "metrics" field name</done>
</task>

</tasks>

<verification>
```bash
go test ./internal/scoring/ -run TestExtractEvidence -v
go test ./internal/output/ -run TestJSONBaseline -v
go test ./... 2>&1 | tail -20
```
All tests pass. No regressions in existing tests.
</verification>

<success_criteria>
- Evidence extraction tests cover all 7 categories (C1-C7) with dedicated subtests
- C1-C3, C6 verify non-empty evidence for metrics with file-level violations
- C4/C5 explicitly verify binary metrics return empty (not nil) slices
- C7 verifies non-nil evidence map with metric keys, each value non-nil
- JSON backward compatibility confirmed for v1 schema
- `go test ./...` passes with no failures
</success_criteria>

<output>
After completion, create `.planning/phases/34-testing-and-quality/34-01-SUMMARY.md`
</output>
